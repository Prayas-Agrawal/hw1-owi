{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTqQIAYS2VgM",
        "outputId": "722fd2b0-af3f-42fb-84f4-f9302c035f70"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://huggingface.co/datasets/VLyb/WN18RR\n",
        "!wget https://download.microsoft.com/download/8/7/0/8700516A-AB3D-4850-B4BB-805C515AECE1/FB15K-237.2.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxxkViXo3fde",
        "outputId": "6b11ea55-721b-430f-aa15-88500e55f5b7"
      },
      "outputs": [],
      "source": [
        "!unzip /content/FB15K-237.2.zip -d /content/FB15K-237"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zsz7JakPrE-"
      },
      "outputs": [],
      "source": [
        "fb15kPathTrain = \"/content/FB15K-237/Release/train.txt\"\n",
        "fb15kPathTest = \"/content/FB15K-237/Release/test.txt\"\n",
        "fb15kPathVal = \"/content/FB15K-237/Release/valid.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auFpf--EBNKt"
      },
      "source": [
        "#Complex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6A3583Z3k69",
        "outputId": "9774da9b-2a24-4c01-b6c8-64b340cdab23"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_PzuB7c4B0i"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualize_graph(G, color):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
        "                     node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_embedding(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    h = h.detach().cpu().numpy()\n",
        "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "    if epoch is not None and loss is not None:\n",
        "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "131Opj2__3uR"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import FB15k_237, WordNet18RR\n",
        "from torch_geometric.nn import ComplEx, DistMult, RotatE, TransE\n",
        "from torch_geometric.transforms import RandomNodeSplit\n",
        "import torch.optim as optim\n",
        "\n",
        "import os\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "path = os.path.join('data', 'FB15k')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D12k9dQb_L7",
        "outputId": "642704d0-f5e3-4524-9851-3b04c0a690c5"
      },
      "outputs": [],
      "source": [
        "train_data = FB15k_237(path, split='train')[0].to(device)\n",
        "val_data = FB15k_237(path, split='val')[0].to(device)\n",
        "test_data = FB15k_237(path, split='test')[0].to(device)\n",
        "\n",
        "# wordnet = WordNet18RR(\"./wordnet\").to(device)\n",
        "# train_data, val_data, test_data = RandomNodeSplit(\n",
        "#         split= 'train_rest'\n",
        "#     )(wordnet)\n",
        "\n",
        "model = ComplEx(\n",
        "    num_nodes=train_data.num_nodes,\n",
        "    num_relations=train_data.num_edge_types,\n",
        "    hidden_channels=50,\n",
        ").to(device)\n",
        "\n",
        "loader = model.loader(\n",
        "    head_index=train_data.edge_index[0],\n",
        "    rel_type=train_data.edge_type,\n",
        "    tail_index=train_data.edge_index[1],\n",
        "    batch_size=1000,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=0.001, weight_decay=1e-6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilIOB_YscYXb"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    total_loss = total_examples = 0\n",
        "    for head_index, rel_type, tail_index in loader:\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(head_index, rel_type, tail_index)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * head_index.numel()\n",
        "        total_examples += head_index.numel()\n",
        "    return total_loss / total_examples\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data, k = 10):\n",
        "    model.eval()\n",
        "    return model.test(\n",
        "        head_index=data.edge_index[0],\n",
        "        rel_type=data.edge_type,\n",
        "        tail_index=data.edge_index[1],\n",
        "        batch_size=20000,\n",
        "        k=k,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zyd76T7Zei-_"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, 501):\n",
        "    loss = train()\n",
        "    if epoch % 25 == 0:\n",
        "        rank, mrr, hits = test(val_data)\n",
        "        print(f'Epoch: {epoch:03d}, Val Mean Rank: {rank:.2f}, '\n",
        "              f'Val MRR: {mrr:.4f}, Val Hits@10: {hits:.4f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rank, mrr, hits_at_10 = test(test_data, k=10)\n",
        "print(f'Test Mean Rank: {rank:.2f}, Test MRR: {mrr:.4f}, '\n",
        "      f'Test Hits@10: {hits_at_10:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rank, mrr, hits_at_1 = test(test_data, k=1)\n",
        "print(f'Test Mean Rank: {rank:.2f}, Test MRR: {mrr:.4f}, '\n",
        "      f'Test Hits@1: {hits_at_1:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBalItaeBIK4"
      },
      "source": [
        "#Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esM_w-GDelKJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfZYgL6FVK99"
      },
      "outputs": [],
      "source": [
        "# Assume professor didnt mean to ask for full contrastive loss other as its extremely slow\n",
        "# Another alternative is, instead relevant embedding(cls/mask) is projected to vocab space like in MLM/BERT\n",
        "def getInbatchNegative(batch, center, dataset=None, vocab=None):\n",
        "  sample = dataset.sample(frac=1000/len(dataset))\n",
        "  # sa = random.sample(self.vocab.items(), 1000)\n",
        "  ret = [torch.tensor(vocab([\"<cls>\", center[\"s\"], \"<sep1>\" ,center[\"r\"],\"<sep2>\" ,data[\"o\"], \"<end>\"])) for data in sample if data[\"o\"] != center[\"o\"]]\n",
        "  # ret = []\n",
        "  # for data in batch:\n",
        "  #   newRow = center\n",
        "  #   newRow[-2] = data[-2]\n",
        "  #   newRow = torch.tensor(newRow)\n",
        "  return torch.tensor(ret)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "  def __init__(self, vocab_size:int, input_dim:int, num_heads:int, num_encoder_layers: int, ff_dim:int, dropout: float):\n",
        "    super().__init__()\n",
        "    # self.posEncoder = None # Check without pos encoding for now\n",
        "    self.input_dim = input_dim\n",
        "    self.pos_encoder = PositionalEncoding(input_dim)\n",
        "    self.embedding = nn.Embedding(vocab_size, input_dim)\n",
        "    encoderLayer = TransformerEncoderLayer(input_dim, num_heads, ff_dim, dropout, )\n",
        "    self.encoder = TransformerEncoder(encoderLayer, num_encoder_layers)\n",
        "    self.maskedGen = nn.Linear(input_dim, vocab_size)\n",
        "    self.score = nn.Linear(input_dim, vocab_size)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self) -> None:\n",
        "    initrange = 0.1\n",
        "    self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "    self.score.bias.data.zero_()\n",
        "    self.score.weight.data.uniform_(-initrange, initrange)\n",
        "    self.maskedGen.bias.data.zero_()\n",
        "    self.maskedGen.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "  def forward(self, x, mask, method):\n",
        "    embeds = self.pos_encoder(self.embedding(x)* np.sqrt(self.input_dim))\n",
        "\n",
        "    contextualEmbeds = self.encoder(embeds)\n",
        "    # print(\"forward\", x.shape, embeds.shape, contextualEmbeds.shape, self.score(contextualEmbeds[:,0]).shape, self.maskedGen(contextualEmbeds[:,-2]).shape)\n",
        "    if(method == 0):\n",
        "      cls = contextualEmbeds[:,0]\n",
        "      return self.score(cls)\n",
        "    else:\n",
        "      maskEmb = contextualEmbeds[:,-2]\n",
        "      return self.maskedGen(maskEmb)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim: int, dropout: float = 0.1, max_len: int = 7):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    position = torch.arange(max_len).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, input_dim, 2) * (-np.log(10000.0) / input_dim))\n",
        "    pe = torch.zeros(max_len, input_dim)\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x: Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "    \"\"\"\n",
        "    # print(\"pos\", x.shape, self.pe.shape)\n",
        "    x = x + self.pe[:x.size(0)]\n",
        "    return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_data(path):\n",
        "  return pd.read_csv(path, delimiter=\"\\t\", names=[\"s\", \"r\", \"o\"])\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, dataset, vocab, transform=None, method = 1):\n",
        "\n",
        "    self.dataset = dataset\n",
        "    self.transform = transform\n",
        "    self.vocab = vocab\n",
        "    self.method = method\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def sample(self, numSamples):\n",
        "    return self.dataset.sample(frac=numSamples/len(self.dataset))\n",
        "\n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    point = self.dataset.iloc[idx]\n",
        "    sample = None\n",
        "    if(self.method == 1): # masked generation\n",
        "      sample = {\n",
        "          \"x\": torch.tensor(vocab([\"<cls>\", point[\"s\"], \"<sep1>\" ,point[\"r\"],\"<sep2>\" ,\"<mask>\", \"<end>\"])),\n",
        "          \"y\":  F.one_hot(torch.tensor(vocab([point[\"o\"]])[0]), len(vocab)).float()\n",
        "      }\n",
        "    else:\n",
        "      sample = {\n",
        "          \"x\": torch.tensor(vocab([\"<cls>\", point[\"s\"], \"<sep1>\" ,point[\"r\"],\"<sep2>\" ,point[\"o\"], \"<end>\"])),\n",
        "          \"y\":  F.one_hot(torch.tensor(vocab([point[\"o\"]])[0]), len(vocab)).float()\n",
        "      }\n",
        "\n",
        "    if(self.transform):\n",
        "      sample = self.transform(sample)\n",
        "    return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fY4oI80--bvX"
      },
      "outputs": [],
      "source": [
        "config2 = {\n",
        "    \"train\": fb15kPathTrain,\n",
        "    \"test\": fb15kPathTest,\n",
        "    \"val\": fb15kPathVal,\n",
        "}\n",
        "\n",
        "config = config2\n",
        "\n",
        "def yieldTokens(data_iter):\n",
        "  for i,row in data_iter.iterrows():\n",
        "    yield [row[\"s\"], row[\"r\"], row[\"o\"]]\n",
        "\n",
        "def yieldSubjectsObjects(data_iter, vocab):\n",
        "  for i,row in data_iter.iterrows():\n",
        "    yield vocab([row[\"s\"], row[\"o\"]])\n",
        "\n",
        "data_iter = read_data(config[\"train\"])\n",
        "vocab = build_vocab_from_iterator(yieldTokens(data_iter), specials=[\"<cls>\", \"<sep1>\", \"<sep2>\", \"<mask>\", \"<end>\", \"<unk>\"])\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "# subObj = yieldSubjectsObjects(data_iter)\n",
        "# subjects = subObj[0]\n",
        "# objects = subObj[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JMvkQwezboE"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(read_data(config[\"train\"]),vocab)\n",
        "val_dataset = CustomDataset(read_data(config[\"val\"]),vocab)\n",
        "test_dataset = CustomDataset(read_data(config[\"test\"]),vocab)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 256, num_workers=2, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size = 256, num_workers=2, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = 256, num_workers=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HKuFUo26sLw",
        "outputId": "9c9abac5-4873-45c0-b0d7-a923057daa02"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Transformer(\n",
        "    dropout=0, vocab_size = len(vocab),\n",
        "    input_dim = 64, num_heads = 2,\n",
        "    num_encoder_layers = 4, ff_dim = 64\n",
        ")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=0.001, weight_decay=1e-6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy-tnCyu8sB1"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, method):\n",
        "  model.train()\n",
        "  total_loss = total_examples = 0\n",
        "  for batchIndex, data in enumerate(loader):\n",
        "    x = data[\"x\"]\n",
        "    y = data[\"y\"]\n",
        "    out = model(x, None, method)\n",
        "    loss = criterion(out, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += float(loss.item())\n",
        "    total_examples += 1\n",
        "\n",
        "    if(batchIndex%50 == 0):\n",
        "      print(f\"epoch {epoch} | {batchIndex}/{len(loader)} | loss: {total_loss / total_examples}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KFIu37aMS9Nk",
        "outputId": "de5a133f-7c46-4241-e289-043e5c88695a"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "method = 1\n",
        "for epoch in range(epochs):\n",
        "  train(model, train_dataloader, method)\n",
        "  print('-' * 89)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM2tK6rzTQDa"
      },
      "outputs": [],
      "source": [
        "def generateSample(dataset, query, sampleSize = 2000, maskMode = \"o\"):\n",
        "    sample = dataset.sample(sampleSize)\n",
        "    ret = []\n",
        "    for _, row in sample.iterrows():\n",
        "      data = query\n",
        "      i = [\"s\", \"r\", \"o\"].index(maskMode)\n",
        "      data[i] = row[i]\n",
        "      ret.append(data)\n",
        "    return np.array(ret)\n",
        "\n",
        "@torch.no_grad()\n",
        "def getTopK(dataset, query, maskMode = \"o\", K=10, sampleSize = 2000):\n",
        "    model.eval()\n",
        "    data = generateSample(dataset, query, sampleSize, maskMode)\n",
        "    dataFrame = pd.DataFrame({'s': data[:, 0], 'r': data[:, 1], 'o': data[:, 2]})\n",
        "    dataset = CustomDataset(dataFrame,vocab)\n",
        "    dataloader = DataLoader(dataset, batch_size = sampleSize, num_workers=2, shuffle=False)\n",
        "    # print(\"load\", data.shape)\n",
        "    out = None\n",
        "    # num batches is just one\n",
        "    for batchIndex, dataBatch in enumerate(dataloader):\n",
        "      x = dataBatch[\"x\"]\n",
        "      y = dataBatch[\"y\"]\n",
        "      out = model(x, None, 1)\n",
        "      # out = out.detach().cpu().numpy()\n",
        "      # x = x.detach().cpu().numpy()\n",
        "      # print(\"x\", x.shape)\n",
        "      # print(\"out\", out.shape)\n",
        "      scores = []\n",
        "      for idx in range(out.shape[0]):\n",
        "        maskedIndex = 1 if maskMode == \"s\" else 5\n",
        "        scores.append([out[idx][x[idx][maskedIndex]]])\n",
        "    scores = np.array(scores)\n",
        "    topK = np.argsort(-scores, axis=0)[:K, :]\n",
        "    # print(\"top k\",K, out.shape, topK.shape, scores.shape, np.argsort(-scores, axis=0).shape)\n",
        "    topKDocs = [data[topK[i][0]] for i in range(topK.shape[0])]\n",
        "    return topKDocs, dataFrame\n",
        "\n",
        "def getGoldLabels(dataset, query, sampledDataset, maskMode = \"o\"):\n",
        "    ret = []\n",
        "    for _, doc in sampledDataset.iterrows():\n",
        "      if(maskMode == \"o\"):\n",
        "        ret.append(1 if(dataset[\"s\"] == doc[\"s\"] and dataset[\"r\"] == doc[\"r\"]) else 0)\n",
        "      elif (maskMode == \"s\"):\n",
        "        ret.append(1 if(dataset[\"r\"] == doc[\"r\"] and dataset[\"o\"] == doc[\"o\"]) else 0)\n",
        "    return ret\n",
        "\n",
        "\n",
        "def getPrecisionTillK(dataset, queries,  maskMode = \"o\", K=10):\n",
        "    ret = [[0 for i in range(K)] for j in range(len(queries))]\n",
        "    for i, query in queries.iterrows():\n",
        "      for k in range(1, K+1):\n",
        "        topK, sampledData = getTopK(dataset, query, maskMode, k)\n",
        "        gold = getGoldLabels(dataset, query, sampledData, maskMode)\n",
        "        goldTopK = [1 if gold[docID] else 0 for docID in topK]\n",
        "        ret[i][k] = np.sum(goldTopK)/len(topK)\n",
        "    return ret\n",
        "\n",
        "\n",
        "def metrics(dataset, numQueries = 1000,  maskMode = \"o\", K=10, sampleSize = 2000):\n",
        "    queries = dataset.sample(numQueries)\n",
        "    ret = []\n",
        "    recall = [0 for i in range(numQueries)]\n",
        "    inverseRankOfFirstGold = [1 for i in range(numQueries)]\n",
        "    precision = [0 for i in range(numQueries)]\n",
        "    for i, query in queries.iterrows():\n",
        "      topK, sampledData = getTopK(dataset, query, maskMode, K, sampleSize = sampleSize)\n",
        "      gold = getGoldLabels(dataset, query, sampledData, maskMode)\n",
        "      goldTopK = [1 if gold[docID] else 0 for docID in topK]\n",
        "      recall[i] = np.sum(goldTopK)/np.sum(gold)\n",
        "      presicionTillK = getPrecisionTillK(dataset, queries, maskMode, K)\n",
        "      precision[i] = np.sum(goldTopK)/len(topK)\n",
        "      inverseRankOfFirstGold[i] = 1/(np.array(goldTopK).toList().index(1) + 1)\n",
        "\n",
        "    hits = np.mean(precision)\n",
        "    mrr = np.mean(inverseRankOfFirstGold)\n",
        "    queryType = \"sr?\" if maskMode == \"o\" else \"?ro\"\n",
        "    print(f\"queryType: {queryType} K:{K} | hits: {hits} | mrr: {mrr}\")\n",
        "    return hits, mrr, map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for K in [1,10]:\n",
        "  for maskMode in [\"o\", \"s\"]:\n",
        "    t = metrics(test_dataset, numQueries = 1000, maskMode = maskMode, K = 10, sampleSize = 2000)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
